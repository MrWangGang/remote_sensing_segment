import os
import random

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms
from PIL import Image
import numpy as np
from tqdm import tqdm
import json
from sklearn.metrics import precision_score, recall_score, jaccard_score, f1_score
import time
import matplotlib.pyplot as plt
from thop import profile

from vitcross_seg_modeling import VisionTransformer, CONFIGS


### --- 1. æ¨¡å‹å’Œè®­ç»ƒè¶…å‚æ•° ---
data_directory = './data'
num_epochs = 10
batch_size = 4
lr = 1e-4

def set_seed(seed):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)  # è¿™é‡Œè®¾ç½®äº†ä¸€ä¸ªéšæœºç§å­

# --- 2. è‡ªå®šä¹‰æ•°æ®é›†ç±» ---
class MyDataset(Dataset):
    def __init__(self, data_path, transform=None, mask_transform=None):
        self.data_path = data_path
        self.transform = transform
        self.mask_transform = mask_transform
        self.intensity_path = os.path.join(data_path, 'imgs', 'intensity')
        self.range_path = os.path.join(data_path, 'imgs', 'range')
        self.masks_path = os.path.join(data_path, 'masks')
        self.image_names = [f for f in os.listdir(self.intensity_path) if f.endswith('.png')]

    def __len__(self):
        return len(self.image_names)

    def __getitem__(self, idx):
        name = self.image_names[idx]
        intensity_img = Image.open(os.path.join(self.intensity_path, name)).convert('RGB')
        range_img = Image.open(os.path.join(self.range_path, name)).convert('RGB')
        mask = Image.open(os.path.join(self.masks_path, name.replace('.png', '.bmp')))

        if self.transform:
            intensity_img = self.transform(intensity_img)
            range_img = self.transform(range_img)

        if self.mask_transform:
            mask = self.mask_transform(mask)

        return intensity_img, range_img, mask.long().squeeze()


# --- 3. æŒ‡æ ‡è®¡ç®—å‡½æ•° ---
def dice_coeff(pred, target, smooth=1.0):
    num_classes = pred.shape[1]
    target_one_hot = torch.nn.functional.one_hot(target, num_classes=num_classes).permute(0, 3, 1, 2).float()
    pred_softmax = torch.nn.functional.softmax(pred, dim=1)

    # è®¡ç®—åŒ…å«èƒŒæ™¯åœ¨å†…çš„æ‰€æœ‰ç±»åˆ«çš„ mDice
    intersection = (pred_softmax * target_one_hot).sum(dim=[2, 3])
    union = (pred_softmax + target_one_hot).sum(dim=[2, 3])

    dice = (2.0 * intersection + smooth) / (union + smooth)
    return dice.mean()

def calculate_metrics(pred, target):
    num_classes = pred.shape[1]
    pred_labels = torch.argmax(pred, dim=1).cpu().numpy().flatten()
    target_labels = target.cpu().numpy().flatten()

    # è®¡ç®—æ‰€æœ‰ç±»åˆ«ï¼ˆåŒ…æ‹¬èƒŒæ™¯ï¼‰çš„ mIoU, mPrecision, mRecall, mF1
    # ä½¿ç”¨ 'macro' å¹³å‡æ–¹å¼ï¼Œè·å–æ¯ä¸ªæŒ‡æ ‡åœ¨æ‰€æœ‰ç±»åˆ«ä¸Šçš„å¹³å‡å€¼
    # 'zero_division=0' ç”¨äºå¤„ç†æŸä¸ªç±»åˆ«ä¸­æ²¡æœ‰æ ·æœ¬çš„æƒ…å†µ
    iou = jaccard_score(target_labels, pred_labels, average='macro', zero_division=0)
    precision = precision_score(target_labels, pred_labels, average='macro', zero_division=0)
    recall = recall_score(target_labels, pred_labels, average='macro', zero_division=0)
    f1 = f1_score(target_labels, pred_labels, average='macro', zero_division=0)

    # mDice å•ç‹¬è®¡ç®—
    dice = dice_coeff(pred, target).item()

    return iou, precision, recall, f1, dice

def save_metrics_to_json(metrics_list, filename='training_metrics.json'):
    with open(filename, 'w') as f:
        json.dump(metrics_list, f, indent=4)
    print(f"âœ… æŒ‡æ ‡å·²ä¿å­˜åˆ° {filename}")

def plot_combined_metrics(filename='training_metrics.json'):
    try:
        with open(filename, 'r') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æŒ‡æ ‡æ–‡ä»¶ {filename}ã€‚")
        return

    epochs = [d['epoch'] for d in data]
    train_losses = [d['train_loss'] for d in data]
    val_losses = [d['val_loss'] for d in data]
    val_ious = [d['val_iou'] for d in data]
    val_dices = [d['val_dice'] for d in data]
    val_precisions = [d['val_precision'] for d in data]
    val_recalls = [d['val_recall'] for d in data]

    # åˆ›å»ºä¸€ä¸ªå¤§çš„å®«æ ¼å›¾ï¼ŒåŒ…å«5ä¸ªå­å›¾
    fig, axs = plt.subplots(3, 2, figsize=(15, 20), constrained_layout=True)

    # ç§»é™¤æœ€åä¸€ä¸ªç©ºçš„å­å›¾
    fig.delaxes(axs[2, 1])

    # å­å›¾1: æŸå¤±æ›²çº¿
    axs[0, 0].plot(epochs, train_losses, label='Train Loss')
    axs[0, 0].plot(epochs, val_losses, label='Validation Loss')
    axs[0, 0].set_title('Loss Curves')
    axs[0, 0].set_xlabel('Epoch')
    axs[0, 0].set_ylabel('Loss')
    axs[0, 0].legend()
    axs[0, 0].grid(True)

    # å­å›¾2: mIoU æ›²çº¿
    axs[0, 1].plot(epochs, val_ious, label='mIoU', color='orange')
    axs[0, 1].set_title('mIoU')
    axs[0, 1].set_xlabel('Epoch')
    axs[0, 1].set_ylabel('Score')
    axs[0, 1].legend()
    axs[0, 1].grid(True)

    # å­å›¾3: mDice æ›²çº¿
    axs[1, 0].plot(epochs, val_dices, label='mDice', color='green')
    axs[1, 0].set_title('mDice')
    axs[1, 0].set_xlabel('Epoch')
    axs[1, 0].set_ylabel('Score')
    axs[1, 0].legend()
    axs[1, 0].grid(True)

    # å­å›¾4: mPrecision æ›²çº¿
    axs[1, 1].plot(epochs, val_precisions, label='mPrecision', color='red')
    axs[1, 1].set_title('mPrecision')
    axs[1, 1].set_xlabel('Epoch')
    axs[1, 1].set_ylabel('Score')
    axs[1, 1].legend()
    axs[1, 1].grid(True)

    # å­å›¾5: mRecall æ›²çº¿
    axs[2, 0].plot(epochs, val_recalls, label='mRecall', color='purple')
    axs[2, 0].set_title('mRecall')
    axs[2, 0].set_xlabel('Epoch')
    axs[2, 0].set_ylabel('Score')
    axs[2, 0].legend()
    axs[2, 0].grid(True)

    plt.suptitle('Training and Validation Metrics', fontsize=20, y=1.02)
    plt.savefig('combined_metrics.png', bbox_inches='tight')
    plt.close()
    print("âœ… æ‰€æœ‰æŒ‡æ ‡æ›²çº¿å·²åˆå¹¶å¹¶ä¿å­˜ä¸º combined_metrics.png")


def save_performance_metrics(model, img_size=(224, 224), filename='model_performance.txt'):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 1. å‚æ•°é‡è®¡ç®—
    total_params = sum(p.numel() for p in model.parameters())

    # 2. FLOPs (æµ®ç‚¹è¿ç®—æ•°) è®¡ç®—
    dummy_input1 = torch.randn(1, 3, img_size[0], img_size[1]).to(device)
    dummy_input2 = torch.randn(1, 3, img_size[0], img_size[1]).to(device)
    flops, _ = profile(model, inputs=(dummy_input1, dummy_input2,), verbose=False)

    # 3. FPS (æ¯ç§’å¸§æ•°) è®¡ç®—
    # çƒ­èº«
    for _ in range(10):
        _ = model(dummy_input1, dummy_input2)

    # è®¡æ—¶
    start_time = time.time()
    num_runs = 100
    for _ in range(num_runs):
        _ = model(dummy_input1, dummy_input2)
    end_time = time.time()

    avg_time = (end_time - start_time) / num_runs
    fps = 1.0 / avg_time

    with open(filename, 'w') as f:
        f.write(f"Model Performance Metrics:\n")
        f.write(f"----------------------------------------\n")
        f.write(f"Total Parameters: {total_params:,}\n")
        f.write(f"FLOPs: {flops / 1e9:.2f} G\n") # è½¬æ¢ä¸º GFLOPs
        f.write(f"Average FPS (on {device}): {fps:.2f}\n")

    print(f"âœ… æ€§èƒ½æŒ‡æ ‡å·²ä¿å­˜åˆ° {filename}")


# --- 4. ä¸»è®­ç»ƒå‡½æ•° ---
def train_model():
    # æ¨¡å‹é…ç½®
    config = CONFIGS['ViT-B_16']
    config.n_classes = 2

    # æ•°æ®é¢„å¤„ç†
    img_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])

    mask_transform = transforms.Compose([
        transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.NEAREST),
        transforms.ToTensor(),
    ])

    # åŠ è½½å’Œåˆ’åˆ†æ•°æ®é›†
    full_dataset = MyDataset(data_directory, transform=img_transform, mask_transform=mask_transform)
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    # å®ä¾‹åŒ–æ¨¡å‹
    model = VisionTransformer(config, img_size=224, num_classes=config.n_classes, vis=False)

    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    print(f"æ¨¡å‹å·²å‡†å¤‡å¥½åœ¨ {device} ä¸Šè¿›è¡Œè®­ç»ƒã€‚")

    metrics_history = []
    best_val_loss = float('inf')  # åˆå§‹åŒ–ä¸€ä¸ªå¤§çš„å€¼æ¥è·Ÿè¸ªæœ€ä½³éªŒè¯æŸå¤±
    best_model_path = 'best_model.pth' # å®šä¹‰æ¨¡å‹ä¿å­˜è·¯å¾„

    # è®­ç»ƒå’ŒéªŒè¯å¾ªç¯
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss_list = []
        train_pbar = tqdm(train_dataloader, desc=f"ç¬¬ {epoch+1}/{num_epochs} è½® (è®­ç»ƒ)", leave=False)
        for intensity_imgs, range_imgs, masks in train_pbar:
            intensity_imgs = intensity_imgs.to(device)
            range_imgs = range_imgs.to(device)
            masks = masks.to(device)

            outputs = model(intensity_imgs, range_imgs)
            loss = criterion(outputs, masks)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss_list.append(loss.item())
            train_pbar.set_postfix({'loss': np.mean(train_loss_list)})

        avg_train_loss = np.mean(train_loss_list)

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss_list = []
        val_dice_list = []
        val_iou_list = []
        val_precision_list = []
        val_recall_list = []
        val_f1_list = []

        val_pbar = tqdm(val_dataloader, desc=f"ç¬¬ {epoch+1}/{num_epochs} è½® (éªŒè¯)", leave=False)
        with torch.no_grad():
            for intensity_imgs, range_imgs, masks in val_pbar:
                intensity_imgs = intensity_imgs.to(device)
                range_imgs = range_imgs.to(device)
                masks = masks.to(device)

                outputs = model(intensity_imgs, range_imgs)
                val_loss = criterion(outputs, masks)
                val_loss_list.append(val_loss.item())

                iou, precision, recall, f1, dice = calculate_metrics(outputs, masks)
                val_iou_list.append(iou)
                val_precision_list.append(precision)
                val_recall_list.append(recall)
                val_f1_list.append(f1)
                val_dice_list.append(dice)

                val_pbar.set_postfix({
                    'loss': np.mean(val_loss_list),
                    'mDice': np.mean(val_dice_list),
                    'mIoU': np.mean(val_iou_list),
                    'mF1': np.mean(val_f1_list)
                })

        avg_val_loss = np.mean(val_loss_list)
        avg_val_dice = np.mean(val_dice_list)
        avg_val_iou = np.mean(val_iou_list)
        avg_val_precision = np.mean(val_precision_list)
        avg_val_recall = np.mean(val_recall_list)
        avg_val_f1 = np.mean(val_f1_list)

        epoch_metrics = {
            "epoch": epoch + 1,
            "train_loss": avg_train_loss,
            "val_loss": avg_val_loss,
            "val_dice": avg_val_dice,
            "val_iou": avg_val_iou,
            "val_precision": avg_val_precision,
            "val_recall": avg_val_recall,
            "val_f1": avg_val_f1
        }
        metrics_history.append(epoch_metrics)

        print(f'ç¬¬ [{epoch+1}/{num_epochs}] è½®')
        print(f'  è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}, éªŒè¯æŸå¤±: {avg_val_loss:.4f}')
        print(f'  éªŒè¯æŒ‡æ ‡: mDice: {avg_val_dice:.4f}, mIoU: {avg_val_iou:.4f}, mPrecision: {avg_val_precision:.4f}, mRecall: {avg_val_recall:.4f}, mF1: {avg_val_f1:.4f}')

        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹å¹¶ä¿å­˜
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(model.state_dict(), best_model_path)
            print(f"ğŸ‰ éªŒè¯æŸå¤±é™ä½è‡³ {best_val_loss:.4f}ã€‚å·²ä¿å­˜æœ€ä½³æ¨¡å‹åˆ° {best_model_path}")

    print("\nè®­ç»ƒå®Œæˆï¼")
    save_metrics_to_json(metrics_history)
    plot_combined_metrics()
    save_performance_metrics(model)


# --- 5. è¿è¡Œè®­ç»ƒ ---
if __name__ == '__main__':
    train_model()